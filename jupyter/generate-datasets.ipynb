{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ongoing-montreal",
   "metadata": {},
   "source": [
    "# Create data set\n",
    "\n",
    "We generate 1 dataset for each number of antennas at the Base-Station (BS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-myanmar",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "trained-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as sig\n",
    "import pandas as pd\n",
    "import utils\n",
    "from typing import Optional\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "from time import time\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-probe",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-engineering",
   "metadata": {},
   "source": [
    "### Generate Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brilliant-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_channels(n_antennas, n_users, n_eve):\n",
    "    # Authentic users' channels\n",
    "    H = np.sqrt(0.5)*(np.random.normal(0, 1, size=(n_antennas, n_users))\n",
    "                      + 1j*np.random.normal(0, 1, size=(n_antennas, n_users)))\n",
    "    \n",
    "    # Eavesdropper channel\n",
    "    g = np.sqrt(0.5)*(np.random.normal(0, 1, size=(n_antennas, n_eve))\n",
    "                      + 1j*np.random.normal(0, 1, size=(n_antennas, n_eve)))\n",
    "    \n",
    "    return H, g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-capture",
   "metadata": {},
   "source": [
    "### Simulate Uplink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "decimal-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_uplink(n_pilot, n_antennas, n_users, n_eve, Pe, snr):\n",
    "    \n",
    "    # Generate channels\n",
    "    Haut, g = gen_channels(int(n_antennas), int(n_users), int(n_eve))\n",
    "    \n",
    "    # Generate QPSK pilot symbols at the users\n",
    "    b = np.random.choice([0, 1], 2*n_pilot*n_users) # The 2 is because a QPSK symbols requires 2 bits\n",
    "    s = utils.qpskmodulator(b)\n",
    "    xp = s.reshape(n_users, n_pilot) # Row k corresponds to the symbols of the k-th user\n",
    "\n",
    "    # generate pilot signal at the eavesdropper:\n",
    "    xpe = np.sqrt(Pe)*xp[0, :] # xp[0, :] corresponds to the pilot sequence of the first user\n",
    "    \n",
    "    # Concatenate signals and channels to simulate transmission\n",
    "    xptx = np.concatenate((xp, [xpe]))\n",
    "    H    = np.concatenate((Haut, g), axis=1) \n",
    "    \n",
    "    # Transmission\n",
    "    Y = np.dot(H, xptx) # Fading\n",
    "    Y = utils.awgn(Y, SNR=snr) # Additive white Gaussian Noise    \n",
    "    \n",
    "    return Y, xp, H[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-census",
   "metadata": {},
   "source": [
    "### Channel Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rocky-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_estimation(Y, xp):\n",
    "    Hest = np.matmul(\n",
    "        np.matmul(Y, np.conjugate(xp).T), \n",
    "        np.linalg.lstsq(\n",
    "            np.matmul(xp, np.conjugate(xp).T), \n",
    "            np.eye(\n",
    "                np.matmul(xp, np.conjugate(xp).T).shape[0], \n",
    "                np.matmul(xp, np.conjugate(xp).T).shape[0]\n",
    "            )\n",
    "        )[0]\n",
    "    )\n",
    "    return Hest[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-promise",
   "metadata": {},
   "source": [
    "### Channel Estimate Energy and Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spread-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_energy(h, snr, n_antennas, n_pilot):\n",
    "    N0       = 1/(10**(snr/10))\n",
    "    sovertau = n_antennas*N0/n_pilot\n",
    "    ln       = np.log((2+sovertau)/(1+sovertau))\n",
    "    eta      = ((1 + sovertau)*(2+sovertau)*ln).real\n",
    "    E        = (np.matmul(np.conjugate(h).T, h)/n_antennas).real\n",
    "    \n",
    "    return E, eta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-tenant",
   "metadata": {},
   "source": [
    "### Generate Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "orange-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(n_pilot, n_antennas, n_users, Pe, snr, n_eve, csv_path):\n",
    "    \n",
    "    # Uplink\n",
    "    Y, xp, h = simulate_uplink(n_pilot, n_antennas, n_users, n_eve, Pe, snr)\n",
    "    \n",
    "    # Channel Estimation\n",
    "    hest = channel_estimation(Y, xp)\n",
    "    \n",
    "    # Energy and threshold for hypothesys test\n",
    "    E, eta = channel_energy(hest, snr, n_antennas, n_pilot)\n",
    "    \n",
    "    # Create label for sample\n",
    "    target = True if Pe else False\n",
    "    \n",
    "    # Save new row in the CSV\n",
    "    linhaNovaCSV = pd.DataFrame([[\n",
    "        n_users,\n",
    "        snr,\n",
    "        E,\n",
    "        eta,\n",
    "        Pe, \n",
    "        target\n",
    "    ]]).to_csv(csv_path, mode=\"a\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-national",
   "metadata": {},
   "source": [
    "## Generate Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-background",
   "metadata": {},
   "source": [
    "### Fixed Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "divided-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pilot = 300\n",
    "n_eve = 1\n",
    "n_trials = 100\n",
    "P = 1 # Users power\n",
    "dirDatasets = Path(\"Data-Sets\")\n",
    "nJobs = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-swedish",
   "metadata": {},
   "source": [
    "### Variable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "corresponding-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_antennas = np.arange(64, 257, 4)\n",
    "range_users    = np.concatenate(([1], np.arange(16, 257, 16)))\n",
    "range_Pe       = np.arange(0, 2.51, 0.5)\n",
    "range_snr      = np.arange(-10, 31, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-waste",
   "metadata": {},
   "source": [
    "### Balancing the cases without pilot contamination\n",
    "\n",
    "There should be the same number of cases with and without PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "appointed-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_Pe = np.concatenate((np.zeros(np.count_nonzero(range_Pe>0) - np.count_nonzero(range_Pe==0)), range_Pe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-repeat",
   "metadata": {},
   "source": [
    "### Generating samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "built-budget",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of antennas:    256\n",
      "Number of users:       256\n",
      "Eve power, Pe:         2.5\n",
      "SNR:                   30\n",
      "Progress:    100.0%\n"
     ]
    }
   ],
   "source": [
    "# Initiating the CSV to save data\n",
    "columns = [\"n_users\", \"snr\", \"E\", \"eta\", \"Pe\", \"target\"]\n",
    "current_iteration = 1\n",
    "total_iterations  = len(range_antennas) * len(range_users) * len(range_snr) * len(range_Pe)\n",
    "\n",
    "for n_antennas in range_antennas:\n",
    "    \n",
    "    # Create one dataset for each number of antennas\n",
    "    df_training = dirDatasets.joinpath(\"train_\"+ str(n_antennas)+\"_antennas.csv\")\n",
    "    df = pd.DataFrame(columns=columns).to_csv(df_training, index=False)\n",
    "    \n",
    "    for n_users in range_users:\n",
    "        for Pe in range_Pe:\n",
    "            for snr in range_snr:\n",
    "                \n",
    "                # PARALELIZANDO\n",
    "                Parallel(n_jobs=nJobs, verbose=0)(\n",
    "                    delayed(generate_sample)(\n",
    "                        n_pilot, \n",
    "                        n_antennas, \n",
    "                        n_users, \n",
    "                        Pe, \n",
    "                        snr, \n",
    "                        n_eve, \n",
    "                        df_training) for trial in range(n_trials))\n",
    "                \n",
    "                # Print information about current iteration\n",
    "                printStr  = \"Number of antennas:    \" + str(n_antennas) + \"\\n\"\n",
    "                printStr += \"Number of users:       \" + str(n_users) + \"\\n\"                \n",
    "                printStr += \"Eve power, Pe:         \" + str(Pe) + \"\\n\"\n",
    "                printStr += \"SNR:                   \" + str(snr) + \"\\n\"\n",
    "                printStr += \"Progress:    \" + str(100*(current_iteration/total_iterations))[:7] + \"%\"\n",
    "                clear_output(wait=True)\n",
    "                print(printStr)\n",
    "                current_iteration += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-emerald",
   "metadata": {},
   "source": [
    "## Generate Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cellular-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pilot = 300\n",
    "n_eve = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eligible-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_antennas = np.arange(64, 257, 4)\n",
    "n_users        = np.concatenate(([1], np.arange(4, 257, 4)))\n",
    "range_Pe       = np.arange(0, 2.51, 0.5)\n",
    "range_snr      = np.arange(-10, 31, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-trunk",
   "metadata": {},
   "source": [
    "### Balancing the cases without pilot contamination\n",
    "\n",
    "There should be the same number of cases with and without PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "secure-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_Pe = np.concatenate((np.zeros(np.count_nonzero(range_Pe>0) - np.count_nonzero(range_Pe==0)), range_Pe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-electric",
   "metadata": {},
   "source": [
    "### Generating Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "welcome-plaza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of antennas:    256\n",
      "Number of users:       256\n",
      "Eve power, Pe:         2.5\n",
      "SNR:                   30\n",
      "Progress:    100.0%\n"
     ]
    }
   ],
   "source": [
    "# Initiating the CSV to save data\n",
    "columns = [\"qtdUsuarios\", \"SNR\", \"E\", \"eta\", \"potenciaEspiao\", \"ataquePresente\"]\n",
    "current_iteration = 1\n",
    "total_iterations  = len(range_antennas) * len(range_users) * len(range_snr) * len(range_Pe)\n",
    "\n",
    "for n_antennas in range_antennas:\n",
    "    \n",
    "    # Create one dataset for each number of antennas\n",
    "    df_test = dirDatasets.joinpath(\"test_\"+ str(n_antennas)+\"_antennas.csv\")\n",
    "    df = pd.DataFrame(columns=columns).to_csv(df_test, index=False)\n",
    "    \n",
    "    for n_users in range_users:\n",
    "        for Pe in range_Pe:\n",
    "            for snr in range_snr:\n",
    "                \n",
    "                # PARALELIZANDO\n",
    "                Parallel(n_jobs=nJobs, verbose=0)(\n",
    "                    delayed(generate_sample)(\n",
    "                        n_pilot, \n",
    "                        n_antennas, \n",
    "                        n_users, \n",
    "                        Pe, \n",
    "                        snr, \n",
    "                        n_eve, \n",
    "                        df_test) for trial in range(n_trials))\n",
    "                \n",
    "                # Print information about current iteration\n",
    "                printStr  = \"Number of antennas:    \" + str(n_antennas) + \"\\n\"\n",
    "                printStr += \"Number of users:       \" + str(n_users) + \"\\n\"                \n",
    "                printStr += \"Eve power, Pe:         \" + str(Pe) + \"\\n\"\n",
    "                printStr += \"SNR:                   \" + str(snr) + \"\\n\"\n",
    "                printStr += \"Progress:    \" + str(100*(current_iteration/total_iterations))[:7] + \"%\"\n",
    "                clear_output(wait=True)\n",
    "                print(printStr)\n",
    "                current_iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501da480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
