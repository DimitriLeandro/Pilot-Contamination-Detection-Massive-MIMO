{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação Probabilidade de Detecção\n",
    "\n",
    "No jupyter anterior, a ideia foi mostrar o comecinho de até onde o ML pode chegar. Aqui a ideia vai ser comparar o desempenho do ML com os algoritmos originais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFININDO ALGUNS PARÂMETROS DO GRÁFICO\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "params = {\n",
    "    'figure.figsize': [12, 3.3], \n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize':14, \n",
    "    'font.size': 12,\n",
    "    'legend.fontsize': 10, \n",
    "    'xtick.labelsize': 10, \n",
    "    'ytick.labelsize': 10,\n",
    "    'axes.axisbelow': True\n",
    "}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição de funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obterDados(qtdUsuarios, qtdAntenas, qtdSimbolos, droparFeatures=None):\n",
    "    \n",
    "    # CONSTRUO O CAMINHO\n",
    "    caminhoCSV = \"../../CSV/dataset_\"+str(qtdUsuarios)+\"usuarios_\"+str(qtdAntenas)+\"antenas_\"+str(qtdSimbolos)+\"simbolos.csv\"    \n",
    "    \n",
    "    # ABRO O CSV\n",
    "    datasetCSV = pd.read_csv(caminhoCSV)\n",
    "    \n",
    "     # DROPANDO AS FEATURES DESEJADAS\n",
    "    if droparFeatures != None:\n",
    "        datasetCSV = datasetCSV.drop(droparFeatures, axis=1)\n",
    "\n",
    "    # SEPARANDO DATA, TARGET, POTENCIA DO ESPIAO E SNR DE CADA DADO\n",
    "    arrayData      = datasetCSV[datasetCSV.columns[:-2]].to_numpy()\n",
    "    arrayTarget    = datasetCSV[datasetCSV.columns[-1]].to_numpy()\n",
    "    arraySNR       = datasetCSV[datasetCSV.columns[0]].to_numpy()\n",
    "    arrayPotEspiao = datasetCSV[datasetCSV.columns[-2]].to_numpy()\n",
    "    \n",
    "    # RETORNO OS DADOS\n",
    "    return arrayData, arrayTarget, arraySNR, arrayPotEspiao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obterValoresUnicos(arraySNR, arrayPotEspiao):\n",
    "    rangeSNRs      = np.unique(arraySNR)\n",
    "    rangePotEspiao = np.unique(arrayPotEspiao)\n",
    "    return rangeSNRs, rangePotEspiao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinarEClassificar(xTrain, xTest, yTrain, classificador):\n",
    "\n",
    "    # TREINANDO O CLASSIFICADOR\n",
    "    objClassificador = eval(classificador)\n",
    "    objClassificador.fit(xTrain, yTrain)\n",
    "\n",
    "    # PREDIZENDO OS DE TESTE\n",
    "    yPred = objClassificador.predict(xTest)\n",
    "        \n",
    "    return yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deteccaoHassan(xTest):\n",
    "    \n",
    "    yPred = []\n",
    "    \n",
    "    for dadoAtual in xTest:\n",
    "        if dadoAtual[1] > dadoAtual[2]:\n",
    "            yPred.append(1)\n",
    "        else:\n",
    "            yPred.append(0)\n",
    "    \n",
    "    return np.array(yPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deteccaoKapetanovic(xTest, threshold):\n",
    "    \n",
    "    yPred = []\n",
    "    \n",
    "    for dadoAtual in xTest:\n",
    "        if dadoAtual[1]/dadoAtual[2] > threshold:\n",
    "            yPred.append(1)\n",
    "        else:\n",
    "            yPred.append(0)\n",
    "    \n",
    "    return np.array(yPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obterMetricas(matrizConfusao):\n",
    "    \n",
    "    acuracia  = 0.0\n",
    "    precisao  = 0.0\n",
    "    revocacao = 0.0\n",
    "    \n",
    "    if np.sum(matrizConfusao) != 0:\n",
    "        acuracia  = (matrizConfusao[0][0]+matrizConfusao[1][1])/np.sum(matrizConfusao)\n",
    "    if (matrizConfusao[1][1] + matrizConfusao[0][1]) != 0:\n",
    "        precisao  = matrizConfusao[1][1]/(matrizConfusao[1][1] + matrizConfusao[0][1])\n",
    "    if (matrizConfusao[1][1] + matrizConfusao[1][0]) != 0:\n",
    "        revocacao = matrizConfusao[1][1]/(matrizConfusao[1][1] + matrizConfusao[1][0])\n",
    "    \n",
    "    return acuracia, precisao, revocacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iniciarJSON(arquivoSalvar):\n",
    "    objFile = open(arquivoSalvar, mode=\"a\")\n",
    "    objFile.write(\"[\")\n",
    "    objFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encerrarJSON(arquivoSalvar):\n",
    "    objFile = open(arquivoSalvar, mode=\"a\")\n",
    "    objFile.write(\"\\n]\")\n",
    "    objFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvarResultado(arquivoSalvar, qtdUsuarios, qtdAntenas, qtdSimbolos, descricao, droparFeatures, repetibilidadeDataset, qtdFolders, rangePotEspiao, rangeSNRs, matrizProbabilidadeDeteccao, matrizConfusao, plotar=True):\n",
    "    \n",
    "    acuracia, precisao, revocacao = obterMetricas(matrizConfusao)\n",
    "    \n",
    "    string  = '\\n{\"qtdUsuarios\":\"' + str(qtdUsuarios)\n",
    "    string += '\",\"qtdAntenas\":\"' + str(qtdAntenas)\n",
    "    string += '\",\"qtdSimbolos\":\"' + str(qtdSimbolos)\n",
    "    string += '\",\"descricao\":\"' + str(descricao)\n",
    "    string += '\",\"droparFeatures\":\"' + str(droparFeatures).replace('\\n', '').replace(' ', ',').replace(',,', ',')\n",
    "    string += '\",\"repetibilidadeDataset\":\"' + str(repetibilidadeDataset)\n",
    "    string += '\",\"qtdFolders\":\"' + str(qtdFolders)\n",
    "    string += '\",\"acuracia\":\"' + str(acuracia)\n",
    "    string += '\",\"precisao\":\"' + str(precisao)\n",
    "    string += '\",\"revocacao\":\"' + str(revocacao)\n",
    "    string += '\",\"rangePotEspiao\":\"' + str(rangePotEspiao).replace('\\n', '').replace(' ', ',').replace(',,', ',')\n",
    "    string += '\",\"rangeSNRs\":\"' + str(rangeSNRs).replace('\\n', '').replace(' ', ',').replace(',,', ',').replace(',,', ',')\n",
    "    string += '\",\"matrizProbabilidadeDeteccao\":\"' + str(matrizProbabilidadeDeteccao).replace('\\n', '').replace(' ', ',').replace(',,', ',').replace(',,', ',')\n",
    "    string += '\",\"matrizConfusao\":\"' + str(matrizConfusao.tolist()).replace('\\n', '').replace(' ', ',').replace(',,', ',') + '\"}'\n",
    "    \n",
    "    if sum(1 for line in open(arquivoSalvar)) != 1:\n",
    "        string = \",\" + string\n",
    "    \n",
    "    objFile = open(arquivoSalvar, mode=\"a\")\n",
    "    objFile.write(string)\n",
    "    objFile.close()\n",
    "    \n",
    "    if plotar == True:\n",
    "        printarResultado(matrizProbabilidadeDeteccao, matrizConfusao, rangePotEspiao, rangeSNRs, qtdUsuarios, qtdAntenas, qtdSimbolos, droparFeatures, acuracia, precisao, revocacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printarResultado(matrizProbabilidadeDeteccao, matrizConfusao, rangePotEspiao, rangeSNRs, qtdUsuarios, qtdAntenas, qtdSimbolos, descricao, acuracia, precisao, revocacao):\n",
    "    \n",
    "    # MONTANDO O TITULO DA FIGURA\n",
    "    titulo  = descricao + \"\\n\"\n",
    "    titulo += \"Usuários: \" + str(qtdUsuarios) + \" - Antenas: \" + str(qtdAntenas) + \" - Símbolos: \" + str(qtdSimbolos) + \"\\n\"\n",
    "    titulo += \"Acurácia: \" + str(acuracia)[:7] + \" - Precisão: \" + str(precisao)[:7] + \" - Revocação: \" + str(revocacao)[:7] + \"\\n\"\n",
    "    \n",
    "    # CRIANDO O PRIMEIRO GRAFICO\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    for i in range(len(rangePotEspiao)):\n",
    "        axs[0].plot(rangeSNRs, matrizProbabilidadeDeteccao[i], label=\"Potência do Espião: \"+str(rangePotEspiao[i]))\n",
    "    axs[0].set_xlabel(\"SNR\")\n",
    "    axs[0].set_ylabel(\"Probabilidade de Detecção\")\n",
    "    axs[0].grid(alpha=0.5)\n",
    "    axs[0].legend()\n",
    "    \n",
    "    # CRIANDO A MATRIZ DE CONFUSAO\n",
    "    axs[1].imshow(matrizConfusao, cmap=\"gray\")\n",
    "    for (j,i), total in np.ndenumerate(matrizConfusao):\n",
    "        axs[1].text(i, j, int(total), ha=\"center\", va=\"center\", color=\"#e6005c\", size=15)\n",
    "    axs[1].set_xlabel(\"Predito\")\n",
    "    axs[1].set_ylabel(\"Real\")\n",
    "    axs[1].set_xticklabels([])\n",
    "    axs[1].set_yticklabels([])\n",
    "    \n",
    "    # PRINTANDO\n",
    "    plt.suptitle(titulo, y=1.15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parâmetros iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador         = \"RandomForestClassifier(n_estimators=10, n_jobs=-1)\"\n",
    "arquivoSalvar         = \"../../Resultados/probabilidadeDeteccao_\" + str(time()) + \".json\"\n",
    "qtdFolders            = 5\n",
    "qtdAntenas            = 256\n",
    "qtdSimbolos           = 128\n",
    "repetibilidadeDataset = 1000\n",
    "rangeQtdUsuarios      = np.array([1, 2, 4, 8, 16, 32, 64, 128, 256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciando o JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iniciarJSON(arquivoSalvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMEÇANDO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando com ML e todas as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "descricao      = \"Detecção baseada em \" + classificador.split(\"(\")[0] + \" com todas as features\"\n",
    "droparFeatures = None\n",
    "\n",
    "# PARA CADA DATASET\n",
    "for qtdUsuarios in rangeQtdUsuarios:\n",
    "    \n",
    "    # PEGO O QUE E O QUE\n",
    "    arrayData, arrayTarget, arraySNR, arrayPotEspiao = obterDados(qtdUsuarios, qtdAntenas, qtdSimbolos, droparFeatures)\n",
    "    \n",
    "    # VALORES UNICOS DE SNR E POTENCIA DE ESPIAO PRA EU SABER O INDEX DAS MATRIZES DE RESULTADOS\n",
    "    rangeSNRs, rangePotEspiao = obterValoresUnicos(arraySNR, arrayPotEspiao)\n",
    "    \n",
    "    # MATRIZES QUE VAO GUARDAR OS RESULTADOS\n",
    "    matrizProbabilidadeDeteccao = np.zeros(shape=(len(rangePotEspiao), len(rangeSNRs)))\n",
    "    matrizConfusao              = np.zeros((2,2))\n",
    "    \n",
    "    # KFOLD\n",
    "    objKFold = KFold(n_splits=qtdFolders, shuffle=True)\n",
    "    for arrayIndexesTreinamento, arrayIndexesTeste in objKFold.split(arrayData):\n",
    "        \n",
    "        # TREINO E TESTE\n",
    "        xTrain, xTest, yTrain, yTest = arrayData[arrayIndexesTreinamento], arrayData[arrayIndexesTeste], arrayTarget[arrayIndexesTreinamento], arrayTarget[arrayIndexesTeste]\n",
    "        \n",
    "        # CLASSIFICACAO\n",
    "        yPred = treinarEClassificar(xTrain, xTest, yTrain, classificador)\n",
    "        \n",
    "        # AGREGO NA CONFUSION MATRIX\n",
    "        matrizConfusao += confusion_matrix(yTest, yPred)\n",
    "        \n",
    "        # AGREGO NA MATRIZ DE PROB DE DETECCAO\n",
    "        for (indexTesteAtual, predicaoAtual) in zip(arrayIndexesTeste, yPred):\n",
    "            \n",
    "            # PEGANDO EM QUAL LINHA E EM QUAL COLUNA DA MATRIZ EU VOU COLOCAR O RESULTADO\n",
    "            indexPotEsp = np.where(rangePotEspiao==arrayPotEspiao[indexTesteAtual])[0][0]\n",
    "            indexSNR    = np.where(rangeSNRs==arraySNR[indexTesteAtual])[0][0]\n",
    "            \n",
    "            # JA SOMO COM A PROBABILIDADE (DIVIDINDO PELA REPETIBILIDADE)\n",
    "            matrizProbabilidadeDeteccao[indexPotEsp][indexSNR] += predicaoAtual/repetibilidadeDataset\n",
    "    \n",
    "    # CONSIDERANDO QUE O DATASET ESTA BALANCEADO, HA MUITO MAIS REPETIBILIDADE QUANDO POTESP = 0\n",
    "    matrizProbabilidadeDeteccao[0] /= (len(rangePotEspiao) - 1)\n",
    "    \n",
    "    # SALVANDO E PRINTANDO\n",
    "    salvarResultado(arquivoSalvar, qtdUsuarios, qtdAntenas, qtdSimbolos, descricao, droparFeatures, repetibilidadeDataset, qtdFolders, rangePotEspiao, rangeSNRs, matrizProbabilidadeDeteccao, matrizConfusao, plotar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando com ML apenas com os autovalores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "descricao      = \"Detecção baseada em \" + classificador.split(\"(\")[0] + \" apenas com os três autovalores do Kapetanovic\"\n",
    "droparFeatures = [\"E\",\"eta\"]\n",
    "\n",
    "# PARA CADA DATASET\n",
    "for qtdUsuarios in rangeQtdUsuarios:\n",
    "    \n",
    "    # PEGO O QUE E O QUE\n",
    "    arrayData, arrayTarget, arraySNR, arrayPotEspiao = obterDados(qtdUsuarios, qtdAntenas, qtdSimbolos, droparFeatures)\n",
    "    \n",
    "    # VALORES UNICOS DE SNR E POTENCIA DE ESPIAO PRA EU SABER O INDEX DAS MATRIZES DE RESULTADOS\n",
    "    rangeSNRs, rangePotEspiao = obterValoresUnicos(arraySNR, arrayPotEspiao)\n",
    "    \n",
    "    # MATRIZES QUE VAO GUARDAR OS RESULTADOS\n",
    "    matrizProbabilidadeDeteccao = np.zeros(shape=(len(rangePotEspiao), len(rangeSNRs)))\n",
    "    matrizConfusao              = np.zeros((2,2))\n",
    "    \n",
    "    # KFOLD\n",
    "    objKFold = KFold(n_splits=qtdFolders, shuffle=True)\n",
    "    for arrayIndexesTreinamento, arrayIndexesTeste in objKFold.split(arrayData):\n",
    "        \n",
    "        # TREINO E TESTE\n",
    "        xTrain, xTest, yTrain, yTest = arrayData[arrayIndexesTreinamento], arrayData[arrayIndexesTeste], arrayTarget[arrayIndexesTreinamento], arrayTarget[arrayIndexesTeste]\n",
    "        \n",
    "        # CLASSIFICACAO\n",
    "        yPred = treinarEClassificar(xTrain, xTest, yTrain, classificador)\n",
    "        \n",
    "        # AGREGO NA CONFUSION MATRIX\n",
    "        matrizConfusao += confusion_matrix(yTest, yPred)\n",
    "        \n",
    "        # AGREGO NA MATRIZ DE PROB DE DETECCAO\n",
    "        for (indexTesteAtual, predicaoAtual) in zip(arrayIndexesTeste, yPred):\n",
    "            \n",
    "            # PEGANDO EM QUAL LINHA E EM QUAL COLUNA DA MATRIZ EU VOU COLOCAR O RESULTADO\n",
    "            indexPotEsp = np.where(rangePotEspiao==arrayPotEspiao[indexTesteAtual])[0][0]\n",
    "            indexSNR    = np.where(rangeSNRs==arraySNR[indexTesteAtual])[0][0]\n",
    "            \n",
    "            # JA SOMO COM A PROBABILIDADE (DIVIDINDO PELA REPETIBILIDADE)\n",
    "            matrizProbabilidadeDeteccao[indexPotEsp][indexSNR] += predicaoAtual/repetibilidadeDataset\n",
    "    \n",
    "    # CONSIDERANDO QUE O DATASET ESTA BALANCEADO, HA MUITO MAIS REPETIBILIDADE QUANDO POTESP = 0\n",
    "    matrizProbabilidadeDeteccao[0] /= (len(rangePotEspiao) - 1) \n",
    "    \n",
    "    # SALVANDO E PRINTANDO\n",
    "    salvarResultado(arquivoSalvar, qtdUsuarios, qtdAntenas, qtdSimbolos, descricao, droparFeatures, repetibilidadeDataset, qtdFolders, rangePotEspiao, rangeSNRs, matrizProbabilidadeDeteccao, matrizConfusao, plotar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando com ML apenas com E e eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "descricao      = \"Detecção baseada em \" + classificador.split(\"(\")[0] + \" apenas com E e eta do Hassan\"\n",
    "droparFeatures = [\"a1\",\"a2\",\"a3\"]\n",
    "\n",
    "# PARA CADA DATASET\n",
    "for qtdUsuarios in rangeQtdUsuarios:\n",
    "    \n",
    "    # PEGO O QUE E O QUE\n",
    "    arrayData, arrayTarget, arraySNR, arrayPotEspiao = obterDados(qtdUsuarios, qtdAntenas, qtdSimbolos, droparFeatures)\n",
    "    \n",
    "    # VALORES UNICOS DE SNR E POTENCIA DE ESPIAO PRA EU SABER O INDEX DAS MATRIZES DE RESULTADOS\n",
    "    rangeSNRs, rangePotEspiao = obterValoresUnicos(arraySNR, arrayPotEspiao)\n",
    "    \n",
    "    # MATRIZES QUE VAO GUARDAR OS RESULTADOS\n",
    "    matrizProbabilidadeDeteccao = np.zeros(shape=(len(rangePotEspiao), len(rangeSNRs)))\n",
    "    matrizConfusao              = np.zeros((2,2))\n",
    "    \n",
    "    # KFOLD\n",
    "    objKFold = KFold(n_splits=qtdFolders, shuffle=True)\n",
    "    for arrayIndexesTreinamento, arrayIndexesTeste in objKFold.split(arrayData):\n",
    "        \n",
    "        # TREINO E TESTE\n",
    "        xTrain, xTest, yTrain, yTest = arrayData[arrayIndexesTreinamento], arrayData[arrayIndexesTeste], arrayTarget[arrayIndexesTreinamento], arrayTarget[arrayIndexesTeste]\n",
    "        \n",
    "        # CLASSIFICACAO\n",
    "        yPred = treinarEClassificar(xTrain, xTest, yTrain, classificador)\n",
    "        \n",
    "        # AGREGO NA CONFUSION MATRIX\n",
    "        matrizConfusao += confusion_matrix(yTest, yPred)\n",
    "        \n",
    "        # AGREGO NA MATRIZ DE PROB DE DETECCAO\n",
    "        for (indexTesteAtual, predicaoAtual) in zip(arrayIndexesTeste, yPred):\n",
    "            \n",
    "            # PEGANDO EM QUAL LINHA E EM QUAL COLUNA DA MATRIZ EU VOU COLOCAR O RESULTADO\n",
    "            indexPotEsp = np.where(rangePotEspiao==arrayPotEspiao[indexTesteAtual])[0][0]\n",
    "            indexSNR    = np.where(rangeSNRs==arraySNR[indexTesteAtual])[0][0]\n",
    "            \n",
    "            # JA SOMO COM A PROBABILIDADE (DIVIDINDO PELA REPETIBILIDADE)\n",
    "            matrizProbabilidadeDeteccao[indexPotEsp][indexSNR] += predicaoAtual/repetibilidadeDataset\n",
    "    \n",
    "    # CONSIDERANDO QUE O DATASET ESTA BALANCEADO, HA MUITO MAIS REPETIBILIDADE QUANDO POTESP = 0\n",
    "    matrizProbabilidadeDeteccao[0] /= (len(rangePotEspiao) - 1)\n",
    "    \n",
    "    # SALVANDO E PRINTANDO\n",
    "    salvarResultado(arquivoSalvar, qtdUsuarios, qtdAntenas, qtdSimbolos, descricao, droparFeatures, repetibilidadeDataset, qtdFolders, rangePotEspiao, rangeSNRs, matrizProbabilidadeDeteccao, matrizConfusao, plotar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando algoritmo do Hassan E>eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "descricao      = \"Detecção baseada no algoritmo do Hassan\"\n",
    "droparFeatures = [\"a1\",\"a2\",\"a3\"]\n",
    "\n",
    "# PARA CADA DATASET\n",
    "for qtdUsuarios in rangeQtdUsuarios:\n",
    "    \n",
    "    # PEGO O QUE E O QUE\n",
    "    arrayData, arrayTarget, arraySNR, arrayPotEspiao = obterDados(qtdUsuarios, qtdAntenas, qtdSimbolos, droparFeatures)\n",
    "    \n",
    "    # VALORES UNICOS DE SNR E POTENCIA DE ESPIAO PRA EU SABER O INDEX DAS MATRIZES DE RESULTADOS\n",
    "    rangeSNRs, rangePotEspiao = obterValoresUnicos(arraySNR, arrayPotEspiao)\n",
    "    \n",
    "    # MATRIZES QUE VAO GUARDAR OS RESULTADOS\n",
    "    matrizProbabilidadeDeteccao = np.zeros(shape=(len(rangePotEspiao), len(rangeSNRs)))\n",
    "    matrizConfusao              = np.zeros((2,2))\n",
    "    \n",
    "    # KFOLD\n",
    "    objKFold = KFold(n_splits=qtdFolders, shuffle=True)\n",
    "    for arrayIndexesTreinamento, arrayIndexesTeste in objKFold.split(arrayData):\n",
    "        \n",
    "        # TREINO E TESTE\n",
    "        xTrain, xTest, yTrain, yTest = arrayData[arrayIndexesTreinamento], arrayData[arrayIndexesTeste], arrayTarget[arrayIndexesTreinamento], arrayTarget[arrayIndexesTeste]\n",
    "        \n",
    "        # CLASSIFICACAO\n",
    "        yPred = deteccaoHassan(xTest)\n",
    "        \n",
    "        # AGREGO NA CONFUSION MATRIX\n",
    "        matrizConfusao += confusion_matrix(yTest, yPred)\n",
    "        \n",
    "        # AGREGO NA MATRIZ DE PROB DE DETECCAO\n",
    "        for (indexTesteAtual, predicaoAtual) in zip(arrayIndexesTeste, yPred):\n",
    "            \n",
    "            # PEGANDO EM QUAL LINHA E EM QUAL COLUNA DA MATRIZ EU VOU COLOCAR O RESULTADO\n",
    "            indexPotEsp = np.where(rangePotEspiao==arrayPotEspiao[indexTesteAtual])[0][0]\n",
    "            indexSNR    = np.where(rangeSNRs==arraySNR[indexTesteAtual])[0][0]\n",
    "            \n",
    "            # JA SOMO COM A PROBABILIDADE (DIVIDINDO PELA REPETIBILIDADE)\n",
    "            matrizProbabilidadeDeteccao[indexPotEsp][indexSNR] += predicaoAtual/repetibilidadeDataset\n",
    "    \n",
    "    # CONSIDERANDO QUE O DATASET ESTA BALANCEADO, HA MUITO MAIS REPETIBILIDADE QUANDO POTESP = 0\n",
    "    matrizProbabilidadeDeteccao[0] /= (len(rangePotEspiao) - 1)\n",
    "    \n",
    "    # SALVANDO E PRINTANDO\n",
    "    salvarResultado(arquivoSalvar, qtdUsuarios, qtdAntenas, qtdSimbolos, descricao, droparFeatures, repetibilidadeDataset, qtdFolders, rangePotEspiao, rangeSNRs, matrizProbabilidadeDeteccao, matrizConfusao, plotar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando algoritmo do Kapetanovic a1/a2 > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "descricao      = \"Detecção baseada no algoritmo do Kapetanovic\"\n",
    "droparFeatures = [\"E\",\"eta\",\"a3\"]\n",
    "\n",
    "# PARA CADA DATASET\n",
    "for qtdUsuarios in rangeQtdUsuarios:\n",
    "    \n",
    "    # PEGO O QUE E O QUE\n",
    "    arrayData, arrayTarget, arraySNR, arrayPotEspiao = obterDados(qtdUsuarios, qtdAntenas, qtdSimbolos, droparFeatures)\n",
    "    \n",
    "    # VALORES UNICOS DE SNR E POTENCIA DE ESPIAO PRA EU SABER O INDEX DAS MATRIZES DE RESULTADOS\n",
    "    rangeSNRs, rangePotEspiao = obterValoresUnicos(arraySNR, arrayPotEspiao)\n",
    "    \n",
    "    # MATRIZES QUE VAO GUARDAR OS RESULTADOS\n",
    "    matrizProbabilidadeDeteccao = np.zeros(shape=(len(rangePotEspiao), len(rangeSNRs)))\n",
    "    matrizConfusao              = np.zeros((2,2))\n",
    "    \n",
    "    # KFOLD\n",
    "    objKFold = KFold(n_splits=qtdFolders, shuffle=True)\n",
    "    for arrayIndexesTreinamento, arrayIndexesTeste in objKFold.split(arrayData):\n",
    "        \n",
    "        # TREINO E TESTE\n",
    "        xTrain, xTest, yTrain, yTest = arrayData[arrayIndexesTreinamento], arrayData[arrayIndexesTeste], arrayTarget[arrayIndexesTreinamento], arrayTarget[arrayIndexesTeste]\n",
    "        \n",
    "        # CLASSIFICACAO\n",
    "        yPred = deteccaoKapetanovic(xTest, 100)\n",
    "        \n",
    "        # AGREGO NA CONFUSION MATRIX\n",
    "        matrizConfusao += confusion_matrix(yTest, yPred)\n",
    "        \n",
    "        # AGREGO NA MATRIZ DE PROB DE DETECCAO\n",
    "        for (indexTesteAtual, predicaoAtual) in zip(arrayIndexesTeste, yPred):\n",
    "            \n",
    "            # PEGANDO EM QUAL LINHA E EM QUAL COLUNA DA MATRIZ EU VOU COLOCAR O RESULTADO\n",
    "            indexPotEsp = np.where(rangePotEspiao==arrayPotEspiao[indexTesteAtual])[0][0]\n",
    "            indexSNR    = np.where(rangeSNRs==arraySNR[indexTesteAtual])[0][0]\n",
    "            \n",
    "            # JA SOMO COM A PROBABILIDADE (DIVIDINDO PELA REPETIBILIDADE)\n",
    "            matrizProbabilidadeDeteccao[indexPotEsp][indexSNR] += predicaoAtual/repetibilidadeDataset\n",
    "    \n",
    "    # CONSIDERANDO QUE O DATASET ESTA BALANCEADO, HA MUITO MAIS REPETIBILIDADE QUANDO POTESP = 0\n",
    "    matrizProbabilidadeDeteccao[0] /= (len(rangePotEspiao) - 1)\n",
    "    \n",
    "    # SALVANDO E PRINTANDO\n",
    "    salvarResultado(arquivoSalvar, qtdUsuarios, qtdAntenas, qtdSimbolos, descricao, droparFeatures, repetibilidadeDataset, qtdFolders, rangePotEspiao, rangeSNRs, matrizProbabilidadeDeteccao, matrizConfusao, plotar=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encerrando o JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encerrarJSON(arquivoSalvar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
